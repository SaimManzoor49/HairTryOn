{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SaimManzoor49/HairTryOn/blob/main/HairTryOn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdIRHddUfCo5",
        "outputId": "ca7b208f-c58d-4f13-988c-ef29e9fca503"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TAfMOvnwfMGg",
        "outputId": "88f8b24b-65bf-4f51-abc8-10331ba8ac1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'Barbershop'...\n",
            "remote: Enumerating objects: 263, done.\u001b[K\n",
            "remote: Counting objects: 100% (61/61), done.\u001b[K\n",
            "remote: Compressing objects: 100% (36/36), done.\u001b[K\n",
            "remote: Total 263 (delta 29), reused 25 (delta 25), pack-reused 202 (from 1)\u001b[K\n",
            "Receiving objects: 100% (263/263), 85.82 MiB | 17.46 MiB/s, done.\n",
            "Resolving deltas: 100% (76/76), done.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!git clone https://github.com/ZPdesu/Barbershop.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2AyCItQKfQc9",
        "outputId": "82ebfbff-a740-4b14-f877-a346fe3805fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/Barbershop\n",
            "align_face.py\t\tdatasets     input    main.py\t\t README.md\n",
            "bash.sh\t\t\tdocs\t     LICENSE  models\t\t unprocessed\n",
            "condacolab_install.log\tenvironment  losses   pretrained_models  utils\n"
          ]
        }
      ],
      "source": [
        "%cd /content/Barbershop\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-XiFQZkfT9G",
        "outputId": "f1488144-163f-41ae-b2e0-186204d60cc4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting condacolab\n",
            "  Downloading condacolab-0.1.10-py3-none-any.whl.metadata (5.5 kB)\n",
            "Downloading condacolab-0.1.10-py3-none-any.whl (7.2 kB)\n",
            "Installing collected packages: condacolab\n",
            "Successfully installed condacolab-0.1.10\n",
            "‚è¨ Downloading https://github.com/jaimergp/miniforge/releases/download/24.11.2-1_colab/Miniforge3-colab-24.11.2-1_colab-Linux-x86_64.sh...\n",
            "üì¶ Installing...\n",
            "üìå Adjusting configuration...\n",
            "ü©π Patching environment...\n",
            "‚è≤ Done in 0:00:09\n",
            "üîÅ Restarting kernel...\n"
          ]
        }
      ],
      "source": [
        "!pip install condacolab\n",
        "import condacolab\n",
        "condacolab.install()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "dQt8h50_fks2"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "# --- Step 1: Create the directory to store the models ---\n",
        "mkdir -p pretrained_models\n",
        "\n",
        "# --- Step 2: Install gdown for reliable Google Drive downloads ---\n",
        "pip install -q gdown\n",
        "\n",
        "# --- Step 3: Download the main FFHQ model (~303MB) ---\n",
        "echo \"Downloading ffhq.pt...\"\n",
        "gdown --id 1AT6bNR2ppK8f2ETL_evT27f3R_oyWNHS -O pretrained_models/ffhq.pt\n",
        "\n",
        "\n",
        "# --- Step 4: Verify the downloads ---\n",
        "echo \"Verification:\"\n",
        "ls -lh pretrained_models/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "CHeKtRhAf7C1",
        "outputId": "529b9a09-f8a2-4e27-dec5-865f89c5a125"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "conda 24.11.2\n"
          ]
        }
      ],
      "source": [
        "!conda --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GoC7GRy_v4to",
        "outputId": "9e268b7b-d253-42b4-caa1-d5a79baba0c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/Barbershop\n",
            "align_face.py\t\tdatasets     input    main.py\t\t README.md\n",
            "bash.sh\t\t\tdocs\t     LICENSE  models\t\t unprocessed\n",
            "condacolab_install.log\tenvironment  losses   pretrained_models  utils\n"
          ]
        }
      ],
      "source": [
        "%cd /content/Barbershop\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IsyVUraZF9Jb"
      },
      "outputs": [],
      "source": [
        "!conda env create -f environment/environment.yml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l11gXih5x6cp",
        "outputId": "aa259bc5-4585-4187-db11-9d85613f94a1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1YaUm9ycCVPvsspgsStPGB6mzm_tmlTPW\n",
            "From (redirected): https://drive.google.com/uc?id=1YaUm9ycCVPvsspgsStPGB6mzm_tmlTPW&confirm=t&uuid=a3351d12-e0bb-4789-bf4a-413d7b71ba11\n",
            "To: /content/hairstyles.zip\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 163M/163M [00:01<00:00, 111MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ 240 images copied to /content/Barbershop/input/face\n"
          ]
        }
      ],
      "source": [
        "import gdown\n",
        "import os\n",
        "from zipfile import ZipFile\n",
        "import shutil\n",
        "\n",
        "# Paths\n",
        "zip_file_path = '/content/hairstyles.zip'\n",
        "extract_path = '/tmp/unzipped_images/'\n",
        "target_folder = '/content/Barbershop/input/face'  # Correct absolute path for Colab\n",
        "\n",
        "# Create necessary directories\n",
        "os.makedirs(extract_path, exist_ok=True)\n",
        "os.makedirs(target_folder, exist_ok=True)\n",
        "\n",
        "# Google Drive file ID\n",
        "file_id = \"1YaUm9ycCVPvsspgsStPGB6mzm_tmlTPW\"\n",
        "gdown.download(f\"https://drive.google.com/uc?id={file_id}\", zip_file_path, quiet=False)\n",
        "\n",
        "# Extract ZIP\n",
        "with ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "# Supported image extensions\n",
        "image_extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.gif')\n",
        "\n",
        "# Recursively copy all images to target_folder\n",
        "image_count = 0\n",
        "for root, dirs, files in os.walk(extract_path):\n",
        "    for file in files:\n",
        "        if file.lower().endswith(image_extensions):\n",
        "            full_path = os.path.join(root, file)\n",
        "            shutil.copy(full_path, target_folder)\n",
        "            image_count += 1\n",
        "\n",
        "print(f\"‚úÖ {image_count} images copied to {target_folder}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDi4yIXYnp3K",
        "outputId": "c4693b84-0c13-4b2a-ce11-e31341ea260d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Channels:\n",
            " - conda-forge\n",
            " - defaults\n",
            " - pytorch\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Solving environment: | \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "    current version: 24.11.2\n",
            "    latest version: 25.5.1\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c conda-forge conda\n",
            "\n",
            "\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local/envs/Barbershop\n",
            "\n",
            "  added / updated specs:\n",
            "    - ninja\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    ca-certificates-2025.7.14  |       hbd8a1cb_0         152 KB  conda-forge\n",
            "    certifi-2024.8.30          |     pyhd8ed1ab_0         160 KB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:         312 KB\n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  ca-certificates    pkgs/main/linux-64::ca-certificates-2~ --> conda-forge/noarch::ca-certificates-2025.7.14-hbd8a1cb_0 \n",
            "  certifi            pkgs/main/linux-64::certifi-2021.10.8~ --> conda-forge/noarch::certifi-2024.8.30-pyhd8ed1ab_0 \n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages:\n",
            "certifi-2024.8.30    | 160 KB    | :   0% 0/1 [00:00<?, ?it/s]\n",
            "ca-certificates-2025 | 152 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "certifi-2024.8.30    | 160 KB    | :  10% 0.10005373980165128/1 [00:00<00:01,  1.73s/it]\n",
            "ca-certificates-2025 | 152 KB    | : 100% 1.0/1 [00:00<00:00,  1.25s/it]                \u001b[A\n",
            "                                                                        \n",
            "                                                                        \u001b[A\n",
            "Preparing transaction: - \b\bdone\n",
            "Verifying transaction: | \b\b/ \b\bdone\n",
            "Executing transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n"
          ]
        }
      ],
      "source": [
        "!conda install -n Barbershop ninja -y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hwiz_6LuoULT"
      },
      "outputs": [],
      "source": [
        "# skip\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# --- 1. Mount your Google Drive ---\n",
        "# This will prompt for authorization if not already mounted.\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# --- 2. Define your paths and environment name ---\n",
        "target_image_path = '/content/drive/MyDrive/face_input/p.jpg'\n",
        "output_folder = '/content/drive/MyDrive/Barbershop_results'\n",
        "env_name = 'Barbershop'\n",
        "\n",
        "# --- 3. Create necessary folders and copy your image for processing ---\n",
        "# The align_face.py script reads from the 'unprocessed' folder.\n",
        "!mkdir -p unprocessed\n",
        "# Also create the final output folder on your Drive ahead of time.\n",
        "!mkdir -p \"{output_folder}\"\n",
        "!cp \"{target_image_path}\" unprocessed/\n",
        "\n",
        "# --- 4. Run the alignment script within the Conda environment ---\n",
        "!source activate {env_name} && python align_face.py\n",
        "\n",
        "# --- 5. Determine the exact name of the preprocessed file ---\n",
        "target_filename_stem = os.path.splitext(os.path.basename(target_image_path))[0]\n",
        "preprocessed_target_filename = f\"{target_filename_stem}.png\"\n",
        "\n",
        "print(\"‚úÖ Preprocessing complete.\")\n",
        "print(f\"Your image '{os.path.basename(target_image_path)}' was processed and saved as 'input/face/{preprocessed_target_filename}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMD4qHHnmhl_"
      },
      "outputs": [],
      "source": [
        "# skip\n",
        "import os\n",
        "\n",
        "# --- 1. Use the preprocessed filename we determined in the previous step ---\n",
        "preprocessed_target_filename = f\"{os.path.splitext(os.path.basename(target_image_path))[0]}.png\"\n",
        "print(f\"Using '{preprocessed_target_filename}' as the identity image.\")\n",
        "\n",
        "# --- 2. Get a list of all available hairstyles ---\n",
        "# We exclude the target's own image from the list of hairstyles to apply.\n",
        "all_hairstyles = [f for f in os.listdir('input/face/') if f != preprocessed_target_filename]\n",
        "print(f\"Found {len(all_hairstyles)} hairstyles to apply.\")\n",
        "\n",
        "# --- 3. Loop through each hairstyle, run the script, and copy the result ---\n",
        "for hair in all_hairstyles:\n",
        "    print(f\"\\n--- Applying hairstyle: {hair} ---\")\n",
        "\n",
        "    # Run the main Barbershop script\n",
        "    !source activate {env_name} && python main.py \\\n",
        "      --im_path1 \"{preprocessed_target_filename}\" \\\n",
        "      --im_path2 \"{hair}\" \\\n",
        "      --im_path3 \"{hair}\" \\\n",
        "      --sign realistic \\\n",
        "      --smooth 5\n",
        "\n",
        "    # After each run, copy the generated output to Google Drive\n",
        "    # This saves progress in case the job is interrupted.\n",
        "    print(f\"--- Saving result for hairstyle {hair} to Google Drive... ---\")\n",
        "    !cp -r output/* \"{output_folder}\"\n",
        "\n",
        "print(f\"\\nüéâ Success! All hairstyles have been processed.\")\n",
        "print(f\"All results have been saved to: {output_folder}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tK8IUDX0tqK_"
      },
      "outputs": [],
      "source": [
        "# it works but slow takes about 20min to process single image\n",
        "import gradio as gr\n",
        "import os\n",
        "import subprocess\n",
        "from PIL import Image\n",
        "import logging\n",
        "import json\n",
        "import base64\n",
        "from io import BytesIO\n",
        "\n",
        "# --- 0. Setup Logging ---\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - [Gradio App] - %(levelname)s - %(message)s',\n",
        "    handlers=[logging.StreamHandler()]\n",
        ")\n",
        "\n",
        "# --- 1. Configuration ---\n",
        "barbershop_dir = '/content/Barbershop'\n",
        "env_name = 'Barbershop'\n",
        "\n",
        "# --- 2. Create Directories ---\n",
        "os.makedirs(os.path.join(barbershop_dir, 'unprocessed'), exist_ok=True)\n",
        "os.makedirs(os.path.join(barbershop_dir, 'output'), exist_ok=True)\n",
        "os.makedirs(os.path.join(barbershop_dir, 'input', 'face'), exist_ok=True)\n",
        "\n",
        "\n",
        "# --- 3. THE FINAL\n",
        "def run_and_stream_command(command_to_run):\n",
        "    \"\"\"\n",
        "    Runs a command inside the conda environment and streams its stdout/stderr\n",
        "    to the console in real-time.\n",
        "    \"\"\"\n",
        "    full_command = f\"conda run --no-capture-output -n {env_name} {command_to_run}\"\n",
        "    logging.info(f\"Executing command: {full_command}\")\n",
        "\n",
        "    # Use Popen to run the command and capture its output stream\n",
        "    process = subprocess.Popen(\n",
        "        full_command,\n",
        "        shell=True,\n",
        "        executable='/bin/bash',\n",
        "        cwd=barbershop_dir,\n",
        "        stdout=subprocess.PIPE,\n",
        "        stderr=subprocess.STDOUT, # Redirect stderr to stdout\n",
        "        text=True,\n",
        "        bufsize=1 # Line-buffered\n",
        "    )\n",
        "\n",
        "    # Read and print the output line by line, in real-time\n",
        "    print(f\"--- Real-time logs from process ---\")\n",
        "    for line in iter(process.stdout.readline, ''):\n",
        "        print(line, end='') # Print the line to the Colab output\n",
        "    print(f\"\\n--- End of real-time logs ---\")\n",
        "\n",
        "    process.stdout.close()\n",
        "    return_code = process.wait()\n",
        "\n",
        "    return return_code\n",
        "\n",
        "\n",
        "# --- 4. API Function Definitions ---\n",
        "\n",
        "def get_hairstyles():\n",
        "    \"\"\"Reads the available hairstyle images and returns them as JSON.\"\"\"\n",
        "    logging.info(\"API CALL: get_hairstyles\")\n",
        "    try:\n",
        "        hairstyles_dir = os.path.join(barbershop_dir, 'input/face')\n",
        "        hairstyles = [f for f in os.listdir(hairstyles_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
        "        hairstyle_data = [{\"filename\": f} for f in hairstyles]\n",
        "        return json.dumps(hairstyle_data, indent=2)\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error in get_hairstyles: {e}\")\n",
        "        return json.dumps({\"error\": str(e)})\n",
        "\n",
        "\n",
        "def apply_hairstyle(user_image, hairstyle_filename):\n",
        "    \"\"\"The main function to process the image with a new hairstyle.\"\"\"\n",
        "    logging.info(\"=\"*50)\n",
        "    logging.info(f\"API CALL: apply_hairstyle with hairstyle: '{hairstyle_filename}'\")\n",
        "\n",
        "    try:\n",
        "        if user_image is None or not hairstyle_filename:\n",
        "            raise gr.Error(\"Validation Error: Both an image and a hairstyle filename are required.\")\n",
        "\n",
        "        # Step A: Save uploaded image\n",
        "        input_filename_stem = \"uploaded_face\"\n",
        "        uploaded_image_path = os.path.join(barbershop_dir, 'unprocessed', f\"{input_filename_stem}.jpg\")\n",
        "        Image.fromarray(user_image).save(uploaded_image_path, \"JPEG\")\n",
        "\n",
        "        # Step B: Run Face Alignment\n",
        "        logging.info(\"--- Starting Face Alignment script ---\")\n",
        "        align_command = \"python align_face.py\"\n",
        "        if run_and_stream_command(align_command) != 0:\n",
        "            raise gr.Error(\"Face alignment script failed. Check the real-time logs above.\")\n",
        "\n",
        "        # Verify output\n",
        "        preprocessed_filename = f\"{input_filename_stem}.png\"\n",
        "        preprocessed_image_path = os.path.join(barbershop_dir, 'input/face', preprocessed_filename)\n",
        "        if not os.path.exists(preprocessed_image_path):\n",
        "            raise gr.Error(\"Alignment script finished but did not create the output file.\")\n",
        "        logging.info(\"--- Face Alignment Complete ---\")\n",
        "\n",
        "        # Step C: Run Main Inference\n",
        "        logging.info(\"--- Starting Inference script ---\")\n",
        "        inference_command = (\n",
        "            f\"python main.py --im_path1 '{preprocessed_filename}' --im_path2 '{hairstyle_filename}' \"\n",
        "            f\"--im_path3 '{hairstyle_filename}' --sign realistic --smooth 5\"\n",
        "        )\n",
        "        if run_and_stream_command(inference_command) != 0:\n",
        "            raise gr.Error(\"Inference script failed. Check the real-time logs above.\")\n",
        "        logging.info(\"--- Inference Script Complete ---\")\n",
        "\n",
        "        # Step D: Locate and return result\n",
        "        hairstyle_base = os.path.splitext(hairstyle_filename)[0]\n",
        "        result_image_path = os.path.join(barbershop_dir, 'output', f'{input_filename_stem}_{hairstyle_base}', 'realistic.png')\n",
        "        if not os.path.exists(result_image_path):\n",
        "            raise gr.Error(\"Inference finished, but the final image was not found.\")\n",
        "\n",
        "        logging.info(\"--- Process Finished Successfully ---\")\n",
        "        return Image.open(result_image_path)\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.critical(f\"An unexpected error occurred: {e}\", exc_info=True)\n",
        "        raise gr.Error(f\"An unexpected server error occurred. See Colab logs for details.\")\n",
        "\n",
        "\n",
        "# --- 5. Create and Launch the Gradio Apps ---\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# Barbershop API Endpoints\")\n",
        "\n",
        "    with gr.Tab(\"Get Hairstyles\"):\n",
        "        gr.Markdown(\"Click the button to get a list of all available hairstyle filenames.\")\n",
        "        get_styles_btn = gr.Button(\"Get All Hairstyles\")\n",
        "        hairstyles_output = gr.JSON(label=\"Available Hairstyles\")\n",
        "        get_styles_btn.click(fn=get_hairstyles, inputs=None, outputs=hairstyles_output, api_name=\"get_hairstyles\")\n",
        "\n",
        "    with gr.Tab(\"Apply Hairstyle\"):\n",
        "        gr.Markdown(\"Upload an image, provide a hairstyle filename, and click Apply.\")\n",
        "        with gr.Row():\n",
        "            input_image = gr.Image(type=\"numpy\", label=\"Upload Face Image\")\n",
        "            with gr.Column():\n",
        "                hairstyle_filename_input = gr.Textbox(label=\"Hairstyle Filename\", placeholder=\"e.g., 15.png\")\n",
        "                submit_button = gr.Button(\"Apply Hairstyle\")\n",
        "        output_image = gr.Image(type=\"pil\", label=\"Result\")\n",
        "\n",
        "        submit_button.click(\n",
        "            fn=apply_hairstyle,\n",
        "            inputs=[input_image, hairstyle_filename_input],\n",
        "            outputs=output_image,\n",
        "            api_name=\"apply_hairstyle\" # This creates the /api/apply_hairstyle/ endpoint\n",
        "        )\n",
        "\n",
        "logging.info(\"Launching Gradio app with two API endpoints...\")\n",
        "demo.queue().launch(share=True, debug=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MzREQaHA8Pa_"
      },
      "outputs": [],
      "source": [
        "# new with optimized performance test if it works\n",
        "\n",
        "import gradio as gr\n",
        "import os\n",
        "import subprocess\n",
        "from PIL import Image\n",
        "import logging\n",
        "import json\n",
        "import base64\n",
        "from io import BytesIO\n",
        "\n",
        "# --- 0. Setup Logging ---\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - [Gradio App] - %(levelname)s - %(message)s',\n",
        "    handlers=[logging.StreamHandler()]\n",
        ")\n",
        "\n",
        "# --- 1. Configuration ---\n",
        "barbershop_dir = '/content/Barbershop'\n",
        "env_name = 'Barbershop'\n",
        "\n",
        "# --- 2. Create Directories ---\n",
        "os.makedirs(os.path.join(barbershop_dir, 'unprocessed'), exist_ok=True)\n",
        "os.makedirs(os.path.join(barbershop_dir, 'output'), exist_ok=True)\n",
        "os.makedirs(os.path.join(barbershop_dir, 'input', 'face'), exist_ok=True)\n",
        "\n",
        "# --- 3. Command Execution Function ---\n",
        "def run_and_stream_command(command_to_run):\n",
        "    \"\"\"\n",
        "    Runs a command inside the conda environment and streams its stdout/stderr\n",
        "    to the console in real-time.\n",
        "    \"\"\"\n",
        "    full_command = f\"conda run --no-capture-output -n {env_name} {command_to_run}\"\n",
        "    logging.info(f\"Executing command: {full_command}\")\n",
        "\n",
        "    process = subprocess.Popen(\n",
        "        full_command,\n",
        "        shell=True,\n",
        "        executable='/bin/bash',\n",
        "        cwd=barbershop_dir,\n",
        "        stdout=subprocess.PIPE,\n",
        "        stderr=subprocess.STDOUT,\n",
        "        text=True,\n",
        "        bufsize=1\n",
        "    )\n",
        "\n",
        "    print(f\"--- Real-time logs from process ---\")\n",
        "    for line in iter(process.stdout.readline, ''):\n",
        "        print(line, end='')\n",
        "    print(f\"\\n--- End of real-time logs ---\")\n",
        "\n",
        "    process.stdout.close()\n",
        "    return_code = process.wait()\n",
        "\n",
        "    return return_code\n",
        "\n",
        "# --- 4. API Function Definitions ---\n",
        "\n",
        "def get_hairstyles():\n",
        "    \"\"\"Reads the available hairstyle images and returns them as JSON.\"\"\"\n",
        "    logging.info(\"API CALL: get_hairstyles\")\n",
        "    try:\n",
        "        hairstyles_dir = os.path.join(barbershop_dir, 'input/face')\n",
        "        hairstyles = [f for f in os.listdir(hairstyles_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
        "        hairstyle_data = [{\"filename\": f} for f in hairstyles]\n",
        "        return json.dumps(hairstyle_data, indent=2)\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error in get_hairstyles: {e}\")\n",
        "        return json.dumps({\"error\": str(e)})\n",
        "\n",
        "\n",
        "def apply_hairstyle(user_image, hairstyle_filename):\n",
        "    \"\"\"The main function to process the image with a new hairstyle.\"\"\"\n",
        "    logging.info(\"=\"*50)\n",
        "    logging.info(f\"API CALL: apply_hairstyle with hairstyle: '{hairstyle_filename}'\")\n",
        "\n",
        "    try:\n",
        "        if user_image is None or not hairstyle_filename:\n",
        "            raise gr.Error(\"Validation Error: Both an image and a hairstyle filename are required.\")\n",
        "\n",
        "        # Step A: Save uploaded image\n",
        "        input_filename_stem = \"uploaded_face\"\n",
        "        uploaded_image_path = os.path.join(barbershop_dir, 'unprocessed', f\"{input_filename_stem}.jpg\")\n",
        "        Image.fromarray(user_image).save(uploaded_image_path, \"JPEG\")\n",
        "\n",
        "        # Step B: Run Face Alignment\n",
        "        logging.info(\"--- Starting Face Alignment script ---\")\n",
        "        align_command = \"python align_face.py\"\n",
        "        if run_and_stream_command(align_command) != 0:\n",
        "            raise gr.Error(\"Face alignment script failed. Check the real-time logs above.\")\n",
        "\n",
        "        preprocessed_filename = f\"{input_filename_stem}.png\"\n",
        "        preprocessed_image_path = os.path.join(barbershop_dir, 'input/face', preprocessed_filename)\n",
        "        if not os.path.exists(preprocessed_image_path):\n",
        "            raise gr.Error(\"Alignment script finished but did not create the output file.\")\n",
        "        logging.info(\"--- Face Alignment Complete ---\")\n",
        "\n",
        "        # Step C: Run Main Inference with Cleanup\n",
        "        logging.info(\"--- Starting Optimized Inference script ---\")\n",
        "        # **MODIFIED COMMAND**: Using main_optimized.py and the --cleanup flag\n",
        "        # inference_command = (\n",
        "        #     f\"python main_optimized.py --im_path1 '{preprocessed_filename}' --im_path2 '{hairstyle_filename}' \"\n",
        "        #     f\"--im_path3 '{hairstyle_filename}' --sign realistic --smooth 5 --cleanup\"\n",
        "        # )\n",
        "\n",
        "        # --- MODIFIED COMMAND WITH REDUCED STEPS ---\n",
        "        inference_command = (\n",
        "          f\"python main_optimized.py --im_path1 '{preprocessed_filename}' --im_path2 '{hairstyle_filename}' \"\n",
        "          f\"--im_path3 '{hairstyle_filename}' --sign realistic --smooth 5 --cleanup \"\n",
        "          f\"--W_steps 300 --FS_steps 100 --align_steps1 50 --align_steps2 50 --blend_steps 150\")\n",
        "        if run_and_stream_command(inference_command) != 0:\n",
        "            raise gr.Error(\"Inference script failed. Check the real-time logs above.\")\n",
        "        logging.info(\"--- Inference Script Complete ---\")\n",
        "\n",
        "        # Step D: Locate and return result\n",
        "        # **CORRECTED PATH**: The final image name is based on the input files.\n",
        "        hairstyle_base = os.path.splitext(hairstyle_filename)[0]\n",
        "        result_image_filename = f\"{input_filename_stem}_{hairstyle_base}_{hairstyle_base}_realistic.png\"\n",
        "        result_image_path = os.path.join(barbershop_dir, 'output', result_image_filename)\n",
        "\n",
        "        if not os.path.exists(result_image_path):\n",
        "            logging.error(f\"Expected result image not found at: {result_image_path}\")\n",
        "            # As a fallback, let's list the contents of the output directory for debugging\n",
        "            output_contents = os.listdir(os.path.join(barbershop_dir, 'output'))\n",
        "            logging.error(f\"Contents of output directory: {output_contents}\")\n",
        "            raise gr.Error(\"Inference finished, but the final image was not found. Check logs for details.\")\n",
        "\n",
        "        logging.info(f\"--- Process Finished Successfully. Result at: {result_image_path} ---\")\n",
        "        return Image.open(result_image_path)\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.critical(f\"An unexpected error occurred: {e}\", exc_info=True)\n",
        "        raise gr.Error(f\"An unexpected server error occurred. See Colab logs for details.\")\n",
        "\n",
        "# --- 5. Create and Launch the Gradio Apps ---\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# Barbershop API Endpoints (Optimized)\")\n",
        "\n",
        "    with gr.Tab(\"Get Hairstyles\"):\n",
        "        gr.Markdown(\"Click the button to get a list of all available hairstyle filenames.\")\n",
        "        get_styles_btn = gr.Button(\"Get All Hairstyles\")\n",
        "        hairstyles_output = gr.JSON(label=\"Available Hairstyles\")\n",
        "        get_styles_btn.click(fn=get_hairstyles, inputs=None, outputs=hairstyles_output, api_name=\"get_hairstyles\")\n",
        "\n",
        "    with gr.Tab(\"Apply Hairstyle\"):\n",
        "        gr.Markdown(\"Upload an image, provide a hairstyle filename, and click Apply. This optimized version will only produce the final image.\")\n",
        "        with gr.Row():\n",
        "            input_image = gr.Image(type=\"numpy\", label=\"Upload Face Image\")\n",
        "            with gr.Column():\n",
        "                hairstyle_filename_input = gr.Textbox(label=\"Hairstyle Filename\", placeholder=\"e.g., 90.png\")\n",
        "                submit_button = gr.Button(\"Apply Hairstyle\")\n",
        "        output_image = gr.Image(type=\"pil\", label=\"Result\")\n",
        "\n",
        "        submit_button.click(\n",
        "            fn=apply_hairstyle,\n",
        "            inputs=[input_image, hairstyle_filename_input],\n",
        "            outputs=output_image,\n",
        "            api_name=\"apply_hairstyle\"\n",
        "        )\n",
        "\n",
        "logging.info(\"Launching Optimized Gradio app with two API endpoints...\")\n",
        "demo.queue().launch(share=True, debug=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "id": "XHTx1U4TQZ16",
        "outputId": "cf90875d-b2ab-4589-e460-26b205a54121"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://c721e3443ab9d88dec.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://c721e3443ab9d88dec.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# new optimized again with selectable images test if it works fine\n",
        "\n",
        "import gradio as gr\n",
        "import os\n",
        "import subprocess\n",
        "from PIL import Image\n",
        "import logging\n",
        "import json\n",
        "from io import BytesIO\n",
        "\n",
        "# --- 0. Setup Logging ---\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - [Gradio App] - %(levelname)s - %(message)s',\n",
        "    handlers=[logging.StreamHandler()]\n",
        ")\n",
        "\n",
        "# --- 1. Configuration ---\n",
        "barbershop_dir = '/content/Barbershop'\n",
        "env_name = 'Barbershop'\n",
        "hairstyles_dir = os.path.join(barbershop_dir, 'input', 'face')\n",
        "\n",
        "\n",
        "# --- 2. Create Directories ---\n",
        "os.makedirs(os.path.join(barbershop_dir, 'unprocessed'), exist_ok=True)\n",
        "os.makedirs(os.path.join(barbershop_dir, 'output'), exist_ok=True)\n",
        "os.makedirs(hairstyles_dir, exist_ok=True)\n",
        "\n",
        "# --- 3. Command Execution Function ---\n",
        "def run_and_stream_command(command_to_run):\n",
        "    \"\"\"\n",
        "    Runs a command inside the conda environment and streams its stdout/stderr\n",
        "    to the console in real-time.\n",
        "    \"\"\"\n",
        "    full_command = f\"conda run --no-capture-output -n {env_name} {command_to_run}\"\n",
        "    logging.info(f\"Executing command: {full_command}\")\n",
        "\n",
        "    process = subprocess.Popen(\n",
        "        full_command,\n",
        "        shell=True,\n",
        "        executable='/bin/bash',\n",
        "        cwd=barbershop_dir,\n",
        "        stdout=subprocess.PIPE,\n",
        "        stderr=subprocess.STDOUT,\n",
        "        text=True,\n",
        "        bufsize=1\n",
        "    )\n",
        "\n",
        "    print(f\"--- Real-time logs from process ---\")\n",
        "    for line in iter(process.stdout.readline, ''):\n",
        "        print(line, end='')\n",
        "    print(f\"\\n--- End of real-time logs ---\")\n",
        "\n",
        "    process.stdout.close()\n",
        "    return_code = process.wait()\n",
        "\n",
        "    return return_code\n",
        "\n",
        "# --- 4. API Function Definitions ---\n",
        "\n",
        "def get_hairstyles_for_api():\n",
        "    \"\"\"Reads the available hairstyle filenames and returns them as JSON for the API.\"\"\"\n",
        "    logging.info(\"API CALL: get_hairstyles_for_api\")\n",
        "    try:\n",
        "        hairstyles = [f for f in os.listdir(hairstyles_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
        "        hairstyle_data = [{\"filename\": f} for f in hairstyles]\n",
        "        return json.dumps(hairstyle_data, indent=2)\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error in get_hairstyles_for_api: {e}\")\n",
        "        return json.dumps({\"error\": str(e)})\n",
        "\n",
        "def get_hairstyle_gallery_data():\n",
        "    \"\"\"Gets a list of hairstyle image paths for display in the Gradio gallery.\"\"\"\n",
        "    logging.info(\"UI CALL: get_hairstyle_gallery_data\")\n",
        "    try:\n",
        "        hairstyle_files = [f for f in os.listdir(hairstyles_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
        "        # Return a list of tuples (image_path, filename) for the gallery\n",
        "        return [(os.path.join(hairstyles_dir, f), f) for f in hairstyle_files]\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error in get_hairstyle_gallery_data: {e}\")\n",
        "        return []\n",
        "\n",
        "def apply_hairstyle(user_image, hairstyle_filename):\n",
        "    \"\"\"The main function to process the image with a new hairstyle.\"\"\"\n",
        "    logging.info(\"=\"*50)\n",
        "    logging.info(f\"API CALL: apply_hairstyle with hairstyle: '{hairstyle_filename}'\")\n",
        "\n",
        "    try:\n",
        "        if user_image is None or not hairstyle_filename:\n",
        "            raise gr.Error(\"Validation Error: Please upload an image and select a hairstyle from the gallery.\")\n",
        "\n",
        "        # Step A: Save uploaded image\n",
        "        input_filename_stem = \"uploaded_face\"\n",
        "        uploaded_image_path = os.path.join(barbershop_dir, 'unprocessed', f\"{input_filename_stem}.jpg\")\n",
        "        Image.fromarray(user_image).save(uploaded_image_path, \"JPEG\")\n",
        "\n",
        "        # Step B: Run Face Alignment\n",
        "        logging.info(\"--- Starting Face Alignment script ---\")\n",
        "        align_command = \"python align_face.py\"\n",
        "        if run_and_stream_command(align_command) != 0:\n",
        "            raise gr.Error(\"Face alignment script failed. Check the real-time logs above.\")\n",
        "\n",
        "        preprocessed_filename = f\"{input_filename_stem}.png\"\n",
        "        preprocessed_image_path = os.path.join(barbershop_dir, 'input/face', preprocessed_filename)\n",
        "        if not os.path.exists(preprocessed_image_path):\n",
        "            raise gr.Error(\"Alignment script finished but did not create the output file.\")\n",
        "        logging.info(\"--- Face Alignment Complete ---\")\n",
        "\n",
        "        # Step C: Run Main Inference with Cleanup\n",
        "        logging.info(\"--- Starting Optimized Inference script ---\")\n",
        "        inference_command = (\n",
        "          f\"python main_optimized.py --im_path1 '{preprocessed_filename}' --im_path2 '{hairstyle_filename}' \"\n",
        "          f\"--im_path3 '{hairstyle_filename}' --sign realistic --smooth 5 --cleanup \"\n",
        "          f\"--W_steps 300 --FS_steps 100 --align_steps1 50 --align_steps2 50 --blend_steps 150\")\n",
        "        if run_and_stream_command(inference_command) != 0:\n",
        "            raise gr.Error(\"Inference script failed. Check the real-time logs above.\")\n",
        "        logging.info(\"--- Inference Script Complete ---\")\n",
        "\n",
        "        # Step D: Locate and return result\n",
        "        hairstyle_base = os.path.splitext(hairstyle_filename)[0]\n",
        "        result_image_filename = f\"{input_filename_stem}_{hairstyle_base}_{hairstyle_base}_realistic.png\"\n",
        "        result_image_path = os.path.join(barbershop_dir, 'output', result_image_filename)\n",
        "\n",
        "        if not os.path.exists(result_image_path):\n",
        "            logging.error(f\"Expected result image not found at: {result_image_path}\")\n",
        "            output_contents = os.listdir(os.path.join(barbershop_dir, 'output'))\n",
        "            logging.error(f\"Contents of output directory: {output_contents}\")\n",
        "            raise gr.Error(\"Inference finished, but the final image was not found. Check logs for details.\")\n",
        "\n",
        "        logging.info(f\"--- Process Finished Successfully. Result at: {result_image_path} ---\")\n",
        "        return Image.open(result_image_path)\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.critical(f\"An unexpected error occurred: {e}\", exc_info=True)\n",
        "        raise gr.Error(f\"An unexpected server error occurred. See Colab logs for details.\")\n",
        "\n",
        "# --- 5. Create and Launch the Gradio Apps ---\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# Barbershop API Endpoints (Optimized)\")\n",
        "\n",
        "    # Hidden state to store the selected hairstyle filename\n",
        "    selected_hairstyle_filename = gr.State(\"\")\n",
        "\n",
        "    with gr.Tab(\"Apply Hairstyle\"):\n",
        "        gr.Markdown(\"1. Upload a clear, front-facing photo. 2. Select a hairstyle from the gallery below. 3. Click 'Apply Hairstyle'.\")\n",
        "        with gr.Row():\n",
        "            input_image = gr.Image(type=\"numpy\", label=\"Upload Face Image\", height=400)\n",
        "            output_image = gr.Image(type=\"pil\", label=\"Result\", height=400)\n",
        "\n",
        "        submit_button = gr.Button(\"Apply Hairstyle\", variant=\"primary\")\n",
        "\n",
        "        gr.Markdown(\"### Available Hairstyles (Click to Select)\")\n",
        "        hairstyle_gallery = gr.Gallery(\n",
        "            label=\"Available Hairstyles\",\n",
        "            value=get_hairstyle_gallery_data,\n",
        "            columns=8,\n",
        "            height=\"auto\",\n",
        "            object_fit=\"cover\"\n",
        "        )\n",
        "\n",
        "        # --- Event Handlers ---\n",
        "        def on_hairstyle_select(evt: gr.SelectData):\n",
        "            \"\"\"Handle the selection of a hairstyle from the gallery.\"\"\"\n",
        "            filename = os.path.basename(evt.value[0]) # evt.value is a tuple (filepath, filename)\n",
        "            gr.Info(f\"Selected hairstyle: {filename}\")\n",
        "            return filename\n",
        "\n",
        "        hairstyle_gallery.select(\n",
        "            fn=on_hairstyle_select,\n",
        "            inputs=None,\n",
        "            outputs=selected_hairstyle_filename,\n",
        "            show_progress=\"hidden\"\n",
        "        )\n",
        "\n",
        "        submit_button.click(\n",
        "            fn=apply_hairstyle,\n",
        "            inputs=[input_image, selected_hairstyle_filename],\n",
        "            outputs=output_image,\n",
        "            api_name=\"apply_hairstyle\"\n",
        "        )\n",
        "\n",
        "    with gr.Tab(\"View All Hairstyles (API)\"):\n",
        "        gr.Markdown(\"This shows all available hairstyle images. The 'apply_hairstyle' API endpoint requires the filename of one of these.\")\n",
        "        with gr.Row():\n",
        "            get_styles_btn = gr.Button(\"Refresh Hairstyle Gallery\")\n",
        "\n",
        "        hairstyles_gallery_output = gr.Gallery(\n",
        "            label=\"Available Hairstyles\",\n",
        "            value=get_hairstyle_gallery_data,\n",
        "            columns=8,\n",
        "            height=\"auto\",\n",
        "            object_fit=\"cover\"\n",
        "        )\n",
        "\n",
        "        # This JSON output is preserved to maintain the original API functionality\n",
        "        hairstyles_json_output = gr.JSON(label=\"Available Hairstyles (API Response)\", visible=False)\n",
        "\n",
        "        get_styles_btn.click(\n",
        "            fn=get_hairstyle_gallery_data,\n",
        "            inputs=None,\n",
        "            outputs=hairstyles_gallery_output\n",
        "        )\n",
        "        # The original API function is still registered\n",
        "        gr.Button(\"Get Hairstyles as JSON\", visible=False).click(\n",
        "            fn=get_hairstyles_for_api,\n",
        "            inputs=None,\n",
        "            outputs=hairstyles_json_output,\n",
        "            api_name=\"get_hairstyles\"\n",
        "        )\n",
        "\n",
        "\n",
        "logging.info(\"Launching Optimized Gradio app with two API endpoints...\")\n",
        "demo.queue().launch(share=True, debug=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyOyqEtfGkzn8m0qOcn690tU",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}